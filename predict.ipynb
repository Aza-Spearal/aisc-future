{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65, 20, 4096])\n"
     ]
    }
   ],
   "source": [
    "loaded_activations  = torch.load('activations.pth')\n",
    "loaded_embeddings = torch.load(\"embeddings.pth\")\n",
    "loaded_residual_stream = torch.load(\"residual_stream.pth\")\n",
    "\n",
    "print(loaded_residual_stream[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([195, 4096]) torch.float16\n",
      "8192\n"
     ]
    }
   ],
   "source": [
    "activations = [i[2][3, -1, :] for i in loaded_activations]\n",
    "residual_stream =  [ torch.stack([i[n, -1, :] for i in loaded_residual_stream]) for n in range(0, 10)]\n",
    "\n",
    "activations = torch.stack(activations)\n",
    "#residual_stream = torch.stack(residual_stream)\n",
    "\n",
    "training =  torch.cat( (torch.cat([residual_stream[i] for i in [3] ], 1), activations), 1 )\n",
    "\n",
    "\n",
    "print(loaded_embeddings.shape, loaded_embeddings.dtype)\n",
    "print(training.shape[1])\n",
    "\n",
    "# Create a complete dataset\n",
    "full_dataset = TensorDataset(training.to(\"cuda\"), loaded_embeddings.to(\"cuda\"))\n",
    "\n",
    "# Define the sizes for your training and validation sets\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for both training and validation sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)  # No need to shuffle the validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImprovedTwoLayerNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ImprovedTwoLayerNN, self).__init__()\n",
    "        # Increase depth and capacity\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(0.5)  # Adjust dropout rate as needed\n",
    "        \n",
    "        # Additional layer\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size * 2)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_size * 2)\n",
    "        self.dropout2 = nn.Dropout(0.5)  # Adjust dropout rate as needed\n",
    "        \n",
    "        # Output layer\n",
    "        self.layer3 = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "class TwoLayerNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,  output_size):\n",
    "        super(TwoLayerNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Training Loss: 22.5960, Validation Loss: 21.2086\n",
      "Epoch [2/40], Training Loss: 19.9887, Validation Loss: 17.0394\n",
      "Epoch [3/40], Training Loss: 15.7569, Validation Loss: 13.9575\n",
      "Epoch [4/40], Training Loss: 13.5084, Validation Loss: 13.3977\n",
      "Epoch [5/40], Training Loss: 12.8835, Validation Loss: 12.3818\n",
      "Epoch [6/40], Training Loss: 11.8563, Validation Loss: 11.8012\n",
      "Epoch [7/40], Training Loss: 11.4453, Validation Loss: 11.7221\n",
      "Epoch [8/40], Training Loss: 11.3480, Validation Loss: 11.4457\n",
      "Epoch [9/40], Training Loss: 11.0023, Validation Loss: 11.0267\n",
      "Epoch [10/40], Training Loss: 10.6200, Validation Loss: 10.8318\n",
      "Epoch [11/40], Training Loss: 10.4886, Validation Loss: 10.7280\n",
      "Epoch [12/40], Training Loss: 10.3536, Validation Loss: 10.5536\n",
      "Epoch [13/40], Training Loss: 10.1843, Validation Loss: 10.4601\n",
      "Epoch [14/40], Training Loss: 10.0995, Validation Loss: 10.3859\n",
      "Epoch [15/40], Training Loss: 10.0171, Validation Loss: 10.2940\n",
      "Epoch [16/40], Training Loss: 9.9262, Validation Loss: 10.2520\n",
      "Epoch [17/40], Training Loss: 9.8744, Validation Loss: 10.2146\n",
      "Epoch [18/40], Training Loss: 9.8069, Validation Loss: 10.1454\n",
      "Epoch [19/40], Training Loss: 9.7471, Validation Loss: 10.0973\n",
      "Epoch [20/40], Training Loss: 9.6930, Validation Loss: 10.0623\n",
      "Epoch [21/40], Training Loss: 9.6388, Validation Loss: 10.0554\n",
      "Epoch [22/40], Training Loss: 9.5814, Validation Loss: 10.0485\n",
      "Epoch [23/40], Training Loss: 9.5385, Validation Loss: 10.0234\n",
      "Epoch [24/40], Training Loss: 9.4825, Validation Loss: 9.9721\n",
      "Epoch [25/40], Training Loss: 9.4294, Validation Loss: 9.9398\n",
      "Epoch [26/40], Training Loss: 9.3863, Validation Loss: 9.9323\n",
      "Epoch [27/40], Training Loss: 9.3505, Validation Loss: 9.9094\n",
      "Epoch [28/40], Training Loss: 9.3162, Validation Loss: 9.8980\n",
      "Epoch [29/40], Training Loss: 9.2663, Validation Loss: 9.8781\n",
      "Epoch [30/40], Training Loss: 9.2405, Validation Loss: 9.8698\n",
      "Epoch [31/40], Training Loss: 9.2019, Validation Loss: 9.8546\n",
      "Epoch [32/40], Training Loss: 9.1733, Validation Loss: 9.8589\n",
      "Epoch [33/40], Training Loss: 9.1371, Validation Loss: 9.8379\n",
      "Epoch [34/40], Training Loss: 9.0948, Validation Loss: 9.8281\n",
      "Epoch [35/40], Training Loss: 9.0699, Validation Loss: 9.8097\n",
      "Epoch [36/40], Training Loss: 9.0329, Validation Loss: 9.7842\n",
      "Epoch [37/40], Training Loss: 8.9877, Validation Loss: 9.7830\n",
      "Epoch [38/40], Training Loss: 8.9567, Validation Loss: 9.7807\n",
      "Epoch [39/40], Training Loss: 8.9144, Validation Loss: 9.7625\n",
      "Epoch [40/40], Training Loss: 8.8734, Validation Loss: 9.7492\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "input_size = training.shape[1]\n",
    "hidden_size = 10000\n",
    "learning_rate = 0.001\n",
    "num_epochs = 40\n",
    "\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "\n",
    "model = TwoLayerNN(input_size, hidden_size, 4096)\n",
    "#model = ImprovedTwoLayerNN(input_size, hidden_size, 4096)\n",
    "\n",
    "model.to(\"cuda\")\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_dataloader:\n",
    "        inputs, targets = inputs.to(\"cuda\").float(), targets.to(\"cuda\").float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():  # No gradients need to be calculated\n",
    "        for inputs, targets in val_dataloader:\n",
    "            inputs, targets = inputs.to(\"cuda\").float(), targets.to(\"cuda\").float()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "    val_loss = running_loss / len(val_dataloader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():  # No gradients needed for inference\n",
    "    for inputs, _ in full_dataset:  # Assuming your dataset returns inputs and targets\n",
    "        inputs = inputs.to('cuda').float().unsqueeze(0)\n",
    "        \n",
    "        # Get the model output\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "\n",
    "        predictions.append(outputs.cpu())\n",
    "\n",
    "# Concatenate all batches of predictions\n",
    "all_predictions = torch.stack(predictions, dim=0)\n",
    "\n",
    "# Save the tensor to a file\n",
    "torch.save(all_predictions, 'model_predictions.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.1851,  1.9739,  1.0377,  ...,  7.0628, -2.4395,  3.3619]]),\n",
       " tensor([[ 0.9378,  2.0632,  1.0800,  ...,  7.1391, -3.1234,  2.7384]]),\n",
       " tensor([[ 1.1774,  2.0113,  1.1116,  ...,  6.8351, -3.0224,  2.9552]]),\n",
       " tensor([[ 1.3200,  1.9634,  0.8198,  ...,  7.2429, -2.2022,  3.5344]]),\n",
       " tensor([[ 1.7550,  1.5351,  1.0508,  ...,  6.6703, -2.7565,  3.5197]]),\n",
       " tensor([[ 1.1092,  1.8253,  0.7763,  ...,  6.5863, -2.6959,  2.7108]]),\n",
       " tensor([[ 1.2174,  1.9298,  0.7212,  ...,  7.0552, -2.4219,  3.1423]]),\n",
       " tensor([[ 0.9978,  1.9279,  1.0411,  ...,  6.2475, -3.1752,  2.4179]]),\n",
       " tensor([[ 1.0171,  1.8925,  0.8713,  ...,  6.4512, -2.7539,  2.5472]]),\n",
       " tensor([[ 1.1101,  2.0591,  0.7049,  ...,  7.0183, -2.8054,  2.6537]]),\n",
       " tensor([[ 1.1161,  2.0581,  0.6805,  ...,  7.2390, -3.4533,  2.3615]]),\n",
       " tensor([[ 0.8318,  1.8835,  1.2477,  ...,  6.3916, -3.1897,  2.3691]]),\n",
       " tensor([[ 1.0533,  1.9651,  0.9165,  ...,  6.8442, -2.7186,  2.7821]]),\n",
       " tensor([[ 0.9381,  1.9861,  0.8526,  ...,  6.6828, -3.1249,  2.3500]]),\n",
       " tensor([[ 0.9619,  2.1079,  0.7928,  ...,  6.6093, -3.4870,  2.0199]]),\n",
       " tensor([[ 0.9795,  2.2338,  0.9135,  ...,  6.9100, -3.4126,  2.3472]]),\n",
       " tensor([[ 1.1600,  2.0311,  0.8167,  ...,  7.1506, -2.8243,  2.8937]]),\n",
       " tensor([[ 1.0365,  2.0124,  0.8190,  ...,  6.7710, -2.6897,  2.7317]]),\n",
       " tensor([[ 1.0098,  1.9977,  0.8537,  ...,  6.4781, -3.2906,  2.2284]]),\n",
       " tensor([[ 1.1173,  1.9956,  0.9702,  ...,  6.5259, -3.0719,  2.5127]]),\n",
       " tensor([[ 1.3273,  1.8021,  0.9764,  ...,  6.9608, -2.0000,  3.6099]]),\n",
       " tensor([[ 1.0602,  2.1059,  0.6411,  ...,  7.1601, -2.7779,  2.6741]]),\n",
       " tensor([[ 1.1627,  2.0883,  1.1976,  ...,  7.0076, -2.8560,  3.1920]]),\n",
       " tensor([[ 1.0638,  2.0940,  0.7413,  ...,  7.1359, -3.0348,  2.5467]]),\n",
       " tensor([[ 1.1765,  2.1236,  1.0135,  ...,  7.1446, -2.2015,  3.5174]]),\n",
       " tensor([[ 0.8778,  1.9959,  0.8798,  ...,  6.7155, -2.9958,  2.4142]]),\n",
       " tensor([[ 1.0746,  2.0986,  0.8852,  ...,  7.0848, -1.9790,  3.4998]]),\n",
       " tensor([[ 1.1760,  2.1265,  1.0072,  ...,  7.1367, -2.2386,  3.4797]]),\n",
       " tensor([[ 1.0746,  2.0986,  0.8852,  ...,  7.0848, -1.9790,  3.4998]]),\n",
       " tensor([[ 1.3213,  1.8069,  0.8691,  ...,  6.9246, -1.8293,  3.6164]]),\n",
       " tensor([[ 1.0728,  2.0818,  0.6141,  ...,  7.1302, -2.7689,  2.6454]]),\n",
       " tensor([[ 1.2015,  2.1069,  1.1568,  ...,  6.9750, -3.1305,  2.9843]]),\n",
       " tensor([[ 1.0205,  2.0395,  0.7327,  ...,  6.8943, -2.9641,  2.4393]]),\n",
       " tensor([[ 1.1878,  2.1417,  1.0140,  ...,  7.1856, -2.2202,  3.5403]]),\n",
       " tensor([[ 0.8545,  1.9674,  0.9173,  ...,  6.6011, -3.0429,  2.3416]]),\n",
       " tensor([[ 1.0746,  2.0986,  0.8852,  ...,  7.0848, -1.9790,  3.4998]]),\n",
       " tensor([[ 1.1521,  2.1355,  1.0106,  ...,  7.0882, -2.2405,  3.4572]]),\n",
       " tensor([[ 1.0746,  2.0986,  0.8852,  ...,  7.0848, -1.9790,  3.4998]]),\n",
       " tensor([[ 1.3114,  1.8070,  0.8401,  ...,  6.9016, -1.8060,  3.5912]]),\n",
       " tensor([[ 1.0580,  2.1889,  0.6625,  ...,  7.1167, -3.2043,  2.3711]]),\n",
       " tensor([[ 1.0616,  2.0670,  1.2979,  ...,  6.8293, -3.1951,  2.8958]]),\n",
       " tensor([[ 1.0400,  2.0397,  0.7188,  ...,  7.0156, -2.7962,  2.6325]]),\n",
       " tensor([[ 1.1872,  2.1407,  1.0082,  ...,  7.1816, -2.2148,  3.5325]]),\n",
       " tensor([[ 0.8883,  2.0398,  0.9598,  ...,  6.8243, -3.1319,  2.4474]]),\n",
       " tensor([[ 1.0746,  2.0986,  0.8852,  ...,  7.0848, -1.9790,  3.4998]]),\n",
       " tensor([[ 1.1693,  2.1341,  1.0302,  ...,  7.1164, -2.2501,  3.4883]]),\n",
       " tensor([[ 1.2361,  1.9734,  1.1283,  ...,  6.8721, -3.4944,  2.6052]]),\n",
       " tensor([[ 1.3120,  1.9272,  0.9040,  ...,  7.2235, -2.9409,  3.0968]]),\n",
       " tensor([[ 0.8722,  2.1786,  1.3887,  ...,  7.0165, -4.3961,  2.0404]]),\n",
       " tensor([[ 1.1824,  1.9529,  0.8924,  ...,  6.9378, -2.5167,  3.1451]]),\n",
       " tensor([[ 0.9470,  2.0701,  1.0232,  ...,  6.9997, -4.0521,  2.0146]]),\n",
       " tensor([[ 1.0198,  1.7042,  0.6326,  ...,  6.4127, -2.8800,  2.2327]]),\n",
       " tensor([[ 0.7879,  1.9747,  0.9773,  ...,  6.5186, -3.8481,  1.7214]]),\n",
       " tensor([[ 0.7566,  2.0665,  1.4372,  ...,  6.0004, -4.0637,  1.8119]]),\n",
       " tensor([[ 1.6865,  1.7873,  0.5584,  ...,  7.2099, -3.9311,  2.0051]]),\n",
       " tensor([[ 1.0032,  2.0935,  1.1147,  ...,  6.7198, -4.1406,  1.8969]]),\n",
       " tensor([[ 0.6693,  2.0532,  1.3747,  ...,  6.3607, -4.7527,  1.4213]]),\n",
       " tensor([[ 1.6088,  1.7694,  0.2683,  ...,  7.0661, -3.3707,  2.0302]]),\n",
       " tensor([[ 1.0807,  2.1508,  0.8236,  ...,  6.9493, -4.0817,  1.7612]]),\n",
       " tensor([[ 0.8697,  2.0979,  1.1169,  ...,  6.5100, -4.0955,  1.7413]]),\n",
       " tensor([[ 1.3511,  2.0015,  0.6143,  ...,  7.0041, -3.8491,  1.9568]]),\n",
       " tensor([[ 1.2329,  2.0293,  0.9729,  ...,  7.0348, -3.5600,  2.4068]]),\n",
       " tensor([[ 1.0339,  1.9358,  0.8818,  ...,  6.6401, -4.0281,  1.8045]]),\n",
       " tensor([[ 1.1247,  1.6686,  0.5619,  ...,  6.7972, -4.1960,  1.4751]]),\n",
       " tensor([[ 0.7786,  2.1596,  1.1638,  ...,  6.8291, -4.1332,  1.8746]]),\n",
       " tensor([[ 1.0393,  1.9158,  0.9462,  ...,  7.1356, -3.1826,  2.5308]]),\n",
       " tensor([[ 1.3192,  2.0397,  0.8937,  ...,  7.2637, -2.9234,  2.9414]]),\n",
       " tensor([[ 1.0274,  1.9070,  0.9154,  ...,  6.3556, -4.1673,  1.4951]]),\n",
       " tensor([[ 1.4607,  1.7437,  0.7037,  ...,  7.3775, -3.2151,  2.4839]]),\n",
       " tensor([[ 3.0837,  0.9469,  0.1509,  ...,  7.7917, -2.8076,  2.9535]]),\n",
       " tensor([[ 0.6176,  2.1746,  1.8835,  ...,  6.4167, -5.2856,  1.3198]]),\n",
       " tensor([[ 0.8288,  2.0706,  1.1124,  ...,  6.4108, -3.8427,  1.8659]]),\n",
       " tensor([[ 1.2982,  1.5006,  0.9142,  ...,  6.6146, -3.0456,  2.4315]]),\n",
       " tensor([[ 0.8304,  1.7905,  0.9904,  ...,  6.1261, -3.7472,  1.7775]]),\n",
       " tensor([[ 0.7613,  1.6731,  0.8573,  ...,  5.8164, -3.6863,  1.4652]]),\n",
       " tensor([[ 1.1526,  1.3535,  1.0034,  ...,  5.9118, -3.0047,  2.2129]]),\n",
       " tensor([[ 1.0419,  1.6245,  0.7738,  ...,  6.9131, -3.7485,  1.9842]]),\n",
       " tensor([[ 0.9457,  1.8534,  0.8474,  ...,  6.6315, -3.9487,  1.7612]]),\n",
       " tensor([[ 1.0237,  1.9904,  0.7718,  ...,  6.6009, -3.0458,  2.3457]]),\n",
       " tensor([[ 0.9054,  2.0881,  1.4902,  ...,  6.3248, -4.6099,  1.7173]]),\n",
       " tensor([[ 1.3644,  1.6335,  0.6792,  ...,  7.3307, -4.4671,  1.5600]]),\n",
       " tensor([[ 1.0369,  1.8754,  1.0054,  ...,  6.5125, -3.3221,  2.3245]]),\n",
       " tensor([[ 0.5840,  2.0851,  1.7604,  ...,  6.3747, -5.3417,  1.1557]]),\n",
       " tensor([[ 0.7624,  2.0479,  1.3431,  ...,  6.2593, -4.1023,  1.8920]]),\n",
       " tensor([[ 0.8899,  1.9280,  1.4801,  ...,  6.7708, -4.1477,  2.1457]]),\n",
       " tensor([[ 0.7583,  1.9607,  1.1877,  ...,  6.5418, -4.1543,  1.5203]]),\n",
       " tensor([[ 0.6521,  1.9564,  1.4747,  ...,  6.0905, -4.5556,  1.4592]]),\n",
       " tensor([[ 1.0441,  1.6770,  0.8377,  ...,  6.4436, -2.6059,  2.5798]]),\n",
       " tensor([[ 1.2690,  1.9632,  0.6106,  ...,  7.2215, -3.0084,  2.5113]]),\n",
       " tensor([[ 0.8018,  2.0376,  1.3426,  ...,  6.0601, -3.9133,  1.9591]]),\n",
       " tensor([[ 0.6262,  2.1255,  1.6186,  ...,  5.9693, -4.7080,  1.3927]]),\n",
       " tensor([[ 1.2243,  2.0748,  0.9089,  ...,  7.2296, -5.0833,  1.4312]]),\n",
       " tensor([[ 0.6681,  2.1317,  1.4512,  ...,  6.0685, -4.6769,  1.3491]]),\n",
       " tensor([[ 0.8078,  2.1346,  1.6759,  ...,  6.0516, -4.6586,  1.6528]]),\n",
       " tensor([[ 1.1145,  1.9506,  0.7892,  ...,  6.7162, -3.7568,  1.9357]]),\n",
       " tensor([[ 1.1805,  2.0663,  0.7669,  ...,  7.1481, -4.3501,  1.7533]]),\n",
       " tensor([[ 0.7204,  2.0247,  1.6045,  ...,  6.4089, -4.4608,  1.7305]]),\n",
       " tensor([[ 0.8285,  1.8114,  1.5821,  ...,  5.7737, -4.1793,  1.6854]]),\n",
       " tensor([[ 1.5112,  1.9119,  0.7910,  ...,  7.1534, -3.9148,  2.0881]]),\n",
       " tensor([[ 1.1984,  1.8362,  0.6796,  ...,  6.9713, -3.8183,  1.8271]]),\n",
       " tensor([[ 0.8967,  2.1495,  1.0716,  ...,  6.4562, -4.2618,  1.5371]]),\n",
       " tensor([[ 0.8654,  1.9977,  1.2438,  ...,  6.3047, -4.3110,  1.6509]]),\n",
       " tensor([[ 1.3133,  1.8302,  0.7563,  ...,  6.6552, -4.3435,  1.5079]]),\n",
       " tensor([[ 0.7754,  2.0368,  1.2158,  ...,  6.2829, -4.2017,  1.7306]]),\n",
       " tensor([[ 0.7347,  2.1592,  1.4762,  ...,  6.1603, -4.9961,  1.2246]]),\n",
       " tensor([[ 1.2641,  1.4374,  0.8645,  ...,  6.7823, -4.4489,  1.3769]]),\n",
       " tensor([[ 1.0319,  1.9132,  0.9032,  ...,  6.2879, -3.6230,  1.8623]]),\n",
       " tensor([[ 0.5453,  2.1514,  1.8026,  ...,  5.9958, -5.1360,  1.2010]]),\n",
       " tensor([[ 1.4430,  1.9048,  0.5335,  ...,  7.1700, -4.0838,  1.7749]]),\n",
       " tensor([[ 0.9072,  2.2411,  1.3657,  ...,  6.5995, -4.6544,  1.5992]]),\n",
       " tensor([[ 1.1718,  1.8212,  0.6328,  ...,  6.6922, -4.5499,  1.2369]]),\n",
       " tensor([[ 1.0083,  1.9673,  0.8246,  ...,  6.5247, -3.5792,  1.9423]]),\n",
       " tensor([[ 0.8618,  2.1224,  1.4190,  ...,  6.2068, -4.3983,  1.7406]]),\n",
       " tensor([[ 1.3979,  1.9867,  0.4493,  ...,  6.6859, -3.7923,  1.7071]]),\n",
       " tensor([[ 1.1486,  1.9932,  0.6709,  ...,  6.5836, -3.7003,  1.8458]]),\n",
       " tensor([[ 0.6891,  2.0575,  1.3703,  ...,  6.0509, -4.5682,  1.3376]]),\n",
       " tensor([[ 1.1442,  2.0269,  0.7615,  ...,  6.3850, -3.8033,  1.7413]]),\n",
       " tensor([[ 1.2342,  2.1026,  0.7293,  ...,  7.1302, -3.9698,  1.9636]]),\n",
       " tensor([[ 0.7742,  2.1040,  0.8993,  ...,  6.6772, -4.0434,  1.5976]]),\n",
       " tensor([[ 0.7136,  1.8331,  0.9574,  ...,  5.9812, -3.6345,  1.6611]]),\n",
       " tensor([[ 1.0510,  1.7085,  0.6623,  ...,  6.5119, -4.2930,  1.3121]]),\n",
       " tensor([[ 1.0480,  1.9803,  0.8877,  ...,  6.0676, -3.8198,  1.6244]]),\n",
       " tensor([[ 1.2101,  1.9276,  1.0098,  ...,  6.9606, -4.2114,  1.9187]]),\n",
       " tensor([[ 0.9694,  1.0367,  1.9686,  ...,  5.9556, -2.8702,  3.4355]]),\n",
       " tensor([[ 1.1074,  2.0063,  0.6601,  ...,  6.5710, -3.6668,  1.7935]]),\n",
       " tensor([[ 0.6742,  1.9186,  1.1045,  ...,  5.9316, -4.2396,  1.2878]]),\n",
       " tensor([[ 1.1836,  1.9122,  0.8727,  ...,  6.9343, -4.3968,  1.7255]]),\n",
       " tensor([[ 1.0584,  2.1789,  1.2169,  ...,  6.9867, -4.3234,  2.0185]]),\n",
       " tensor([[ 1.4291,  1.9758,  0.5856,  ...,  7.1989, -3.9116,  1.9342]]),\n",
       " tensor([[ 0.6889,  1.8099,  0.8904,  ...,  5.6514, -3.3533,  1.5924]]),\n",
       " tensor([[ 0.6772,  2.0860,  1.4008,  ...,  5.9981, -4.8110,  1.2920]]),\n",
       " tensor([[ 1.2376,  1.8171,  0.6147,  ...,  6.9077, -3.9341,  1.7399]]),\n",
       " tensor([[ 1.5420,  2.0040,  0.7477,  ...,  7.5805, -4.1821,  2.1641]]),\n",
       " tensor([[ 1.2241,  1.9517,  0.7737,  ...,  6.7101, -4.5482,  1.4312]]),\n",
       " tensor([[ 0.7878,  1.9069,  1.3043,  ...,  6.1559, -3.3081,  2.1745]]),\n",
       " tensor([[ 0.9114,  1.8899,  1.1241,  ...,  6.4201, -4.2310,  1.5852]]),\n",
       " tensor([[ 0.7245,  1.8439,  1.1980,  ...,  5.9796, -4.6272,  1.1109]]),\n",
       " tensor([[ 1.3296,  1.6847,  0.3382,  ...,  6.8860, -3.6463,  1.7392]]),\n",
       " tensor([[ 0.8765,  1.9210,  1.1495,  ...,  6.2048, -4.1013,  1.7170]]),\n",
       " tensor([[ 0.9407,  2.1014,  1.0619,  ...,  6.7505, -4.4048,  1.5968]]),\n",
       " tensor([[ 1.1419,  2.0392,  0.6019,  ...,  6.5071, -4.3956,  1.2009]]),\n",
       " tensor([[ 1.1712,  1.8504,  0.5453,  ...,  6.8546, -3.9077,  1.6554]]),\n",
       " tensor([[ 1.3810,  1.9538,  0.7954,  ...,  6.8833, -4.1173,  1.8616]]),\n",
       " tensor([[ 1.0993,  1.8691,  0.6826,  ...,  5.8035, -3.5883,  1.5460]]),\n",
       " tensor([[ 1.2040,  2.0587,  0.8478,  ...,  6.7953, -4.5892,  1.4687]]),\n",
       " tensor([[ 0.9096,  2.0839,  1.1815,  ...,  6.6321, -4.1959,  1.8631]]),\n",
       " tensor([[ 1.5280,  2.0838,  0.4464,  ...,  7.3835, -4.4582,  1.6606]]),\n",
       " tensor([[ 0.6163,  2.0651,  1.7714,  ...,  6.0808, -4.7744,  1.5234]]),\n",
       " tensor([[ 1.3113,  2.0150,  0.5786,  ...,  7.1965, -3.7962,  2.0404]]),\n",
       " tensor([[ 1.0002,  2.0757,  0.9491,  ...,  6.6913, -3.9192,  1.8488]]),\n",
       " tensor([[ 1.1341,  2.0522,  0.6756,  ...,  6.7701, -4.3842,  1.3865]]),\n",
       " tensor([[ 1.5575,  1.7356,  0.9352,  ...,  6.8008, -3.8104,  2.1353]]),\n",
       " tensor([[ 0.9187,  2.1458,  1.0362,  ...,  6.3957, -3.6736,  1.9719]]),\n",
       " tensor([[ 1.2161,  2.0181,  0.6319,  ...,  6.8246, -4.2516,  1.5120]]),\n",
       " tensor([[ 1.2067,  2.0610,  0.7985,  ...,  6.6803, -3.8195,  1.9174]]),\n",
       " tensor([[ 1.3943,  1.9994,  0.3122,  ...,  7.1582, -3.6057,  1.9472]]),\n",
       " tensor([[ 0.9073,  2.0207,  1.2097,  ...,  6.1888, -4.1424,  1.6227]]),\n",
       " tensor([[ 1.3558,  1.9267,  0.5464,  ...,  7.1070, -3.3058,  2.2745]]),\n",
       " tensor([[ 1.0447,  2.1663,  0.9588,  ...,  6.7053, -3.8982,  1.9676]]),\n",
       " tensor([[ 0.6065,  2.1139,  1.2822,  ...,  6.1463, -4.3747,  1.4427]]),\n",
       " tensor([[ 1.3153,  1.9331,  0.6155,  ...,  6.8264, -4.0455,  1.6763]]),\n",
       " tensor([[ 0.9753,  2.0214,  0.8129,  ...,  5.7708, -4.0360,  1.2777]]),\n",
       " tensor([[ 1.1202,  1.9561,  0.7386,  ...,  6.8640, -4.3349,  1.4786]]),\n",
       " tensor([[ 1.1293,  2.0987,  0.8392,  ...,  5.9757, -3.7944,  1.6668]]),\n",
       " tensor([[ 1.3690,  1.9918,  0.6240,  ...,  7.0967, -4.0806,  1.7715]]),\n",
       " tensor([[ 0.9809,  2.0387,  1.0807,  ...,  6.5369, -2.8672,  2.6939]]),\n",
       " tensor([[ 1.1165,  2.0924,  0.9165,  ...,  6.7138, -4.1145,  1.8170]]),\n",
       " tensor([[ 1.1772,  1.9864,  0.7620,  ...,  6.7142, -4.0301,  1.6616]]),\n",
       " tensor([[ 1.0808,  2.0904,  0.6808,  ...,  6.8782, -3.8408,  1.8114]]),\n",
       " tensor([[ 0.9049,  2.0862,  1.1337,  ...,  6.5491, -3.9781,  1.9269]]),\n",
       " tensor([[ 1.1165,  2.1930,  0.8594,  ...,  7.0676, -4.4087,  1.6995]]),\n",
       " tensor([[ 1.0892,  2.0057,  0.6221,  ...,  6.5398, -3.7616,  1.6957]]),\n",
       " tensor([[ 1.1705,  2.1342,  0.7962,  ...,  7.2485, -4.1720,  1.8554]]),\n",
       " tensor([[ 0.9004,  2.1208,  0.9887,  ...,  6.0329, -3.9520,  1.6308]]),\n",
       " tensor([[ 0.9881,  2.0410,  0.8185,  ...,  6.5435, -3.3473,  2.0675]]),\n",
       " tensor([[ 0.8931,  1.9670,  0.9362,  ...,  6.3451, -3.7042,  1.7903]]),\n",
       " tensor([[ 1.1555,  2.1944,  0.6802,  ...,  6.8599, -4.4014,  1.4898]]),\n",
       " tensor([[ 0.8608,  2.3484,  1.1402,  ...,  6.7355, -4.0279,  1.9861]]),\n",
       " tensor([[ 1.0851,  1.9505,  0.6921,  ...,  6.7176, -3.5378,  2.0679]]),\n",
       " tensor([[ 1.1205,  2.0494,  0.7234,  ...,  6.6307, -3.8058,  1.7895]]),\n",
       " tensor([[ 1.3122,  1.9983,  0.5673,  ...,  7.0370, -3.7265,  1.9912]]),\n",
       " tensor([[ 1.1435,  2.1091,  0.8834,  ...,  7.0590, -3.9257,  2.0748]]),\n",
       " tensor([[ 1.2178,  1.8600,  0.5261,  ...,  6.4677, -3.3275,  1.8450]]),\n",
       " tensor([[ 1.2605,  1.9659,  0.8012,  ...,  6.4427, -3.8665,  1.7876]]),\n",
       " tensor([[ 0.9451,  2.0846,  0.7766,  ...,  6.8112, -3.9340,  1.7683]]),\n",
       " tensor([[ 0.8665,  2.2042,  0.9650,  ...,  6.5528, -4.1544,  1.6296]]),\n",
       " tensor([[ 1.2443,  2.1587,  0.6322,  ...,  6.9803, -4.3446,  1.6482]]),\n",
       " tensor([[ 0.8889,  1.9979,  0.8760,  ...,  6.4002, -3.4463,  2.0103]]),\n",
       " tensor([[ 1.3022,  2.0405,  0.6357,  ...,  6.6618, -4.4331,  1.4462]]),\n",
       " tensor([[ 1.1971,  2.0628,  0.8426,  ...,  7.0125, -3.7560,  2.1411]]),\n",
       " tensor([[ 1.0687,  2.0573,  0.8465,  ...,  6.6893, -3.8092,  1.8839]]),\n",
       " tensor([[ 1.0256,  2.1147,  0.9522,  ...,  6.4822, -3.9134,  1.8598]]),\n",
       " tensor([[ 1.1215,  1.9624,  0.7283,  ...,  6.4695, -3.5835,  1.8212]]),\n",
       " tensor([[ 0.7659,  2.0923,  1.0760,  ...,  6.0579, -3.7628,  1.7544]]),\n",
       " tensor([[ 1.2797,  2.1044,  0.5575,  ...,  7.2069, -4.2417,  1.6728]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
